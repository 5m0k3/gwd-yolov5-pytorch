{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV5 Inference Notebook with Pseudo Labelling using train + test images\n",
    "Designed for single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurations for Pseudo Labelling\n",
    "Designed for Kaggle Code competition with internet restrictions so takes offline datasets as input. Change the directories as required while reproducing locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "NMS_IOU_THR = 0.6\n",
    "NMS_CONF_THR = 0.5\n",
    "\n",
    "# WBF\n",
    "best_iou_thr = 0.6 # 0.9 - best but timeout (9+ hrs)\n",
    "best_skip_box_thr = 0.43 # 0.1 - best but timeout (9+ hrs)\n",
    "\n",
    "# Box conf threshold\n",
    "best_final_score = 0\n",
    "best_score_threshold = 0.0    # This value is for base model, used only in makePL func\n",
    "\n",
    "EPO = (50+15)    # Base model epochs + desired PL epochs, this resume issue is fixed in my provided local repo\n",
    "\n",
    "WEIGHTS = '../input/mixup50e/last_yolov5x_4M50fold0.pt'\n",
    "\n",
    "CONFIG = '../input/configyolo5/yolov5x.yaml'\n",
    "\n",
    "DATA = '../input/configyolo5/wheat0.yaml'\n",
    "\n",
    "is_TEST = len(os.listdir('../input/global-wheat-detection/test/'))>11\n",
    "\n",
    "is_AUG = True\n",
    "is_ROT = True\n",
    "\n",
    "VALIDATE = True\n",
    "\n",
    "PSEUDO = True\n",
    "\n",
    "# For OOF evaluation\n",
    "marking = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "\n",
    "bboxs = np.stack(marking['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "    marking[column] = bboxs[:,i]\n",
    "marking.drop(columns=['bbox'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#!cp -r ../input/yolov5train/* .\n",
    "!cp -r ../input/y5mixuprepo/yolov5-mixup/* .\n",
    "sys.path.insert(0, \"../input/weightedboxesfusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convertTrainLabel():\n",
    "    df = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "    for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "        df[column] = bboxs[:,i]\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    df['x_center'] = df['x'] + df['w']/2\n",
    "    df['y_center'] = df['y'] + df['h']/2\n",
    "    df['classes'] = 0\n",
    "    df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n",
    "    \n",
    "    index = list(set(df.image_id))\n",
    "    \n",
    "    source = 'train'\n",
    "    if True:\n",
    "        for fold in [0]:\n",
    "            val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
    "            fold=0\n",
    "            for name, mini in tqdm(df.groupby('image_id')):\n",
    "                path2save = 'val2017/' if name in val_index else 'train2017/'\n",
    "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save, exist_ok=True)\n",
    "                with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                    row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                    row = row/1024\n",
    "                    row = row.astype(str)\n",
    "                    for j in range(len(row)):\n",
    "                        text = ' '.join(row[j])\n",
    "                        f.write(text)\n",
    "                        f.write(\"\\n\")\n",
    "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save), exist_ok=True)\n",
    "                sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TTA (Test-Time-Augmentations) and Thresholds Optimizing Functions\n",
    "To be used in Pseudo Labelling - covered in detail in [CV] Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "code_folding": [
     2,
     9,
     26,
     37
    ]
   },
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "\n",
    "def run_wbf(boxes, scores, image_size=1024, iou_thr=0.5, skip_box_thr=0.7, weights=None):\n",
    "    labels = [np.zeros(score.shape[0]) for score in scores]\n",
    "    boxes = [box/(image_size) for box in boxes]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def TTAImage(image, index):\n",
    "    image1 = image.copy()\n",
    "    if index==0: \n",
    "        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image\n",
    "    elif index==1:\n",
    "        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image2\n",
    "    elif index==2:\n",
    "        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image3\n",
    "    elif index == 3:\n",
    "        return image1\n",
    "    \n",
    "def rotBoxes90(boxes, im_w, im_h):\n",
    "    ret_boxes =[]\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n",
    "        x1, y1, x2, y2 = y1, -x1, y2, -x2\n",
    "        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n",
    "        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n",
    "        ret_boxes.append([x1a, y1a, x2a, y2a])\n",
    "    return np.array(ret_boxes)\n",
    "\n",
    "def detect1Image(img, img0, model, device, aug):\n",
    "    img = img.transpose(2,0,1)\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img =  img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    \n",
    "    # Inference\n",
    "    pred = model(img, augment=aug)[0]\n",
    "    \n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, NMS_CONF_THR, NMS_IOU_THR, merge=True, classes=None, agnostic=False)\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        # save_path = 'draw/' + image_id + '.jpg'\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n",
    "                scores.append(conf)\n",
    "\n",
    "    return np.array(boxes), np.array(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# validate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "import re\n",
    "import cv2\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import jit\n",
    "from typing import List, Union, Tuple\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # for pred_idx, pred in enumerate(preds_sorted):\n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision\n",
    "\n",
    "    \n",
    "# Numba typed list!\n",
    "iou_thresholds = numba.typed.List()\n",
    "\n",
    "for x in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75]:\n",
    "    iou_thresholds.append(x)\n",
    "    \n",
    "def validate():\n",
    "    source = 'convertor/fold0/images/val2017'\n",
    "    \n",
    "    weights = 'weights/best.pt'\n",
    "    if not os.path.exists(weights):\n",
    "        weights = WEIGHTS\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=1024)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for path, img, img0, vid_cap in dataset:\n",
    "            \n",
    "        image_id = os.path.basename(path).split('.')[0]\n",
    "        img = img.transpose(1,2,0) # [H, W, 3]\n",
    "        \n",
    "        enboxes = []\n",
    "        enscores = []\n",
    "        \n",
    "        # only rot, no flip\n",
    "        if is_ROT:    \n",
    "            for i in range(4):\n",
    "                img1 = TTAImage(img, i)\n",
    "                boxes, scores = detect1Image(img1, img0, model, device, aug=is_AUG)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n",
    "                enboxes.append(boxes)\n",
    "                enscores.append(scores) \n",
    "        \n",
    "        # flip\n",
    "        \"\"\"boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n",
    "        enboxes.append(boxes)\n",
    "        enscores.append(scores)\"\"\"\n",
    "            \n",
    "        #boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=WBF_IOU_THR, skip_box_thr=WBF_CONF_THR)    \n",
    "        #boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n",
    "        #boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        #boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        #boxes = boxes[scores >= 0.05].astype(np.int32)\n",
    "        #scores = scores[scores >= float(0.05)]\n",
    "        \n",
    "        records = marking[marking['image_id'] == image_id]\n",
    "        gtboxes = records[['x', 'y', 'w', 'h']].values\n",
    "        gtboxes = gtboxes.astype(np.int32).clip(min=0, max=1024)\n",
    "        gtboxes[:, 2] = gtboxes[:, 0] + gtboxes[:, 2]\n",
    "        gtboxes[:, 3] = gtboxes[:, 1] + gtboxes[:, 3]\n",
    "        \n",
    "            \n",
    "        result = {\n",
    "            'image_id': image_id,\n",
    "            'pred_enboxes': enboxes, # xyhw\n",
    "            'pred_enscores': enscores,\n",
    "            'gt_boxes': gtboxes, # xyhw\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def calculate_final_score(all_predictions, iou_thr, skip_box_thr, score_threshold):\n",
    "    final_scores = []\n",
    "    for i in range(len(all_predictions)):\n",
    "        gt_boxes = all_predictions[i]['gt_boxes'].copy()\n",
    "        enboxes = all_predictions[i]['pred_enboxes'].copy()\n",
    "        enscores = all_predictions[i]['pred_enscores'].copy()\n",
    "        image_id = all_predictions[i]['image_id']\n",
    "        \n",
    "        pred_boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=iou_thr, skip_box_thr=skip_box_thr)    \n",
    "        pred_boxes = pred_boxes.astype(np.int32).clip(min=0, max=1024)\n",
    "\n",
    "        indexes = np.where(scores>score_threshold)\n",
    "        pred_boxes = pred_boxes[indexes]\n",
    "        scores = scores[indexes]\n",
    "\n",
    "        image_precision = calculate_image_precision(gt_boxes, pred_boxes,thresholds=iou_thresholds,form='pascal_voc')\n",
    "        final_scores.append(image_precision)\n",
    "\n",
    "    return np.mean(final_scores)\n",
    "\n",
    "def show_result(sample_id, preds, gt_boxes):\n",
    "    sample = cv2.imread(f'../input/global-wheat-detection/train/{sample_id}.jpg', cv2.IMREAD_COLOR)\n",
    "    sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "    for pred_box in preds:\n",
    "        cv2.rectangle(\n",
    "            sample,\n",
    "            (pred_box[0], pred_box[1]),\n",
    "            (pred_box[2], pred_box[3]),\n",
    "            (220, 0, 0), 2\n",
    "        )\n",
    "\n",
    "    for gt_box in gt_boxes:    \n",
    "        cv2.rectangle(\n",
    "            sample,\n",
    "            (gt_box[0], gt_box[1]),\n",
    "            (gt_box[2], gt_box[3]),\n",
    "            (0, 0, 220), 2\n",
    "        )\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(sample)\n",
    "    ax.set_title(\"RED: Predicted | BLUE - Ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Bayesian Optimize\n",
    "\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_objective, plot_evaluations, plot_convergence, plot_regret\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "\n",
    "def log(text):\n",
    "    print(text)\n",
    "\n",
    "def optimize(space, all_predictions, n_calls=10):\n",
    "    @use_named_args(space)\n",
    "    def score(**params):\n",
    "        log('-'*10)\n",
    "        log(params)\n",
    "        final_score = calculate_final_score(all_predictions, **params)\n",
    "        log(f'final_score = {final_score}')\n",
    "        log('-'*10)\n",
    "        return -final_score\n",
    "\n",
    "    return gp_minimize(func=score, dimensions=space, n_calls=n_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "def makePseudolabel():\n",
    "    source = '../input/global-wheat-detection/test/'\n",
    "    weights = WEIGHTS\n",
    "    \n",
    "    imagenames =  os.listdir(source)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=1024)\n",
    "\n",
    "    path2save = 'train2017/'\n",
    "    \n",
    "    if not os.path.exists('convertor/fold0/labels/'+path2save):\n",
    "        os.makedirs('convertor/fold0/labels/'+path2save)\n",
    "    if not os.path.exists('convertor/fold0/images/{}'.format(path2save)):\n",
    "        os.makedirs('convertor/fold0/images/{}'.format(path2save))\n",
    "    \n",
    "    for path, img, img0, vid_cap in dataset:\n",
    "        image_id = os.path.basename(path).split('.')[0]\n",
    "        img = img.transpose(1,2,0) # [H, W, 3]\n",
    "        \n",
    "        enboxes = []\n",
    "        enscores = []\n",
    "        \n",
    "        # only rot, no flip\n",
    "        if is_ROT:    \n",
    "            for i in range(4):\n",
    "                img1 = TTAImage(img, i)\n",
    "                boxes, scores = detect1Image(img1, img0, model, device, aug=is_AUG)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n",
    "                enboxes.append(boxes)\n",
    "                enscores.append(scores) \n",
    "        \n",
    "        # flip\n",
    "        \"\"\"boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n",
    "        enboxes.append(boxes)\n",
    "        enscores.append(scores)\"\"\" \n",
    "            \n",
    "        boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=best_iou_thr, skip_box_thr=best_skip_box_thr)\n",
    "        boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n",
    "        \n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        indices = scores >= best_score_threshold\n",
    "        boxes = boxes[indices]\n",
    "        scores = scores[indices]\n",
    "        \n",
    "        lineo = ''\n",
    "        for box in boxes:\n",
    "            x1, y1, w, h = box\n",
    "            xc, yc, w, h = (x1+w/2)/1024, (y1+h/2)/1024, w/1024, h/1024\n",
    "            lineo += '0 %f %f %f %f\\n'%(xc, yc, w, h)\n",
    "            \n",
    "        fileo = open('convertor/fold0/labels/'+path2save+image_id+\".txt\", 'w+')\n",
    "        fileo.write(lineo)\n",
    "        fileo.close()\n",
    "        sh.copy(\"../input/global-wheat-detection/test/{}.jpg\".format(image_id),'convertor/fold0/images/{}/{}.jpg'.format(path2save,image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3373/3373 [00:14<00:00, 236.18it/s]\n"
     ]
    }
   ],
   "source": [
    "if PSEUDO or VALIDATE:\n",
    "    convertTrainLabel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pseudo Labels Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/10 ../input/global-wheat-detection/test/2fd875eaa.jpg: image 2/10 ../input/global-wheat-detection/test/348a992bb.jpg: image 3/10 ../input/global-wheat-detection/test/51b3e36ab.jpg: image 4/10 ../input/global-wheat-detection/test/51f1be19e.jpg: image 5/10 ../input/global-wheat-detection/test/53f253011.jpg: image 6/10 ../input/global-wheat-detection/test/796707dd7.jpg: image 7/10 ../input/global-wheat-detection/test/aac893a91.jpg: image 8/10 ../input/global-wheat-detection/test/cb8d261a3.jpg: image 9/10 ../input/global-wheat-detection/test/cc3532ff6.jpg: image 10/10 ../input/global-wheat-detection/test/f5a1f0358.jpg: "
     ]
    }
   ],
   "source": [
    "if PSEUDO:\n",
    "    makePseudolabel()\n",
    "    \n",
    "    if is_TEST:\n",
    "        !python train.py --weights {WEIGHTS} --img 1024 --batch 4 --epochs {EPO} --data {DATA} --cfg {CONFIG}\n",
    "    else:\n",
    "        pass\n",
    "        #!python train.py --weights {WEIGHTS} --img 1024 --batch 2 --epochs 1 --data {DATA} --cfg {CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if VALIDATE and is_TEST:\n",
    "    all_predictions = validate()\n",
    "    \n",
    "    for score_threshold in tqdm(np.arange(0, 1, 0.01), total=np.arange(0, 1, 0.01).shape[0]):\n",
    "        final_score = calculate_final_score(all_predictions, best_iou_thr, best_skip_box_thr, score_threshold)\n",
    "        if final_score > best_final_score:\n",
    "            best_final_score = final_score\n",
    "            best_score_threshold = score_threshold\n",
    "\n",
    "    print('-'*30)\n",
    "    print(f'[Best Score Threshold]: {best_score_threshold}')\n",
    "    print(f'[OOF Score]: {best_final_score:.4f}')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "\n",
    "    return \" \".join(pred_strings)\n",
    "\n",
    "def detect():\n",
    "    source = '../input/global-wheat-detection/test/'\n",
    "    weights = 'weights/best.pt'\n",
    "    if not os.path.exists(weights):\n",
    "        weights = WEIGHTS\n",
    "    \n",
    "    imagenames =  os.listdir(source)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=1024)\n",
    "\n",
    "    results = []\n",
    "    fig, ax = plt.subplots(5, 2, figsize=(30, 70))\n",
    "    count = 0\n",
    "    \n",
    "    for path, img, img0, vid_cap in dataset:\n",
    "        image_id = os.path.basename(path).split('.')[0]\n",
    "        img = img.transpose(1,2,0) # [H, W, 3]\n",
    "        \n",
    "        enboxes = []\n",
    "        enscores = []\n",
    "        \n",
    "        # only rot, no flip\n",
    "        if is_ROT:    \n",
    "            for i in range(4):\n",
    "                img1 = TTAImage(img, i)\n",
    "                boxes, scores = detect1Image(img1, img0, model, device, aug=is_AUG)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n",
    "                enboxes.append(boxes)\n",
    "                enscores.append(scores) \n",
    "        \n",
    "        # flip\n",
    "        \"\"\"boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n",
    "        enboxes.append(boxes)\n",
    "        enscores.append(scores)\"\"\"\n",
    "            \n",
    "        boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=best_iou_thr, skip_box_thr=best_skip_box_thr)    \n",
    "        boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        indices = scores >= best_score_threshold\n",
    "        boxes = boxes[indices]\n",
    "        scores = scores[indices]\n",
    "        \n",
    "        if count<10:\n",
    "            img_ = cv2.imread(path)  # BGR\n",
    "            for box, score in zip(boxes,scores):\n",
    "                cv2.rectangle(img_, (box[0], box[1]), (box[2]+box[0], box[3]+box[1]), (220, 0, 0), 2)\n",
    "                cv2.putText(img_, '%.2f'%(score), (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "            ax[count%5][count//5].imshow(img_)\n",
    "            count+=1\n",
    "            \n",
    "        result = {\n",
    "            'image_id': image_id,\n",
    "            'PredictionString': format_prediction_string(boxes, scores)\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detect()\n",
    "test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n",
    "#!rm -rf ./*\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
